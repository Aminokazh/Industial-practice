{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2de796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9531a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "custom_stopwords = {\n",
    "    'это', 'очень', 'просто', 'ещё', 'такой', 'нужно', 'вообще', 'чтото', 'что',\n",
    "    'которые', 'было', 'будет', 'можно', 'нельзя', 'только', 'самый',\n",
    "    'нам', 'вам', 'без', 'при', 'всё', 'него', 'она', 'они', 'какой', 'разные', 'другие','некоторые', 'быть'\n",
    "}\n",
    "stop_words = set(stopwords.words('russian')) | custom_stopwords\n",
    "\n",
    "synonyms = {\n",
    "    \"задача\": \"задание\",\n",
    "    \"задачи\": \"задание\",\n",
    "    \"задач\": \"задание\",\n",
    "    \"заданий\": \"задание\"\n",
    "}\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^а-яa-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words and len(token) > 2:\n",
    "            lemma = morph.parse(token)[0].normal_form\n",
    "            lemma = synonyms.get(lemma, lemma)\n",
    "            if lemma not in stop_words:\n",
    "                lemmas.append(lemma)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d918a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.read_excel(\"pos_reviews.xlsx\")\n",
    "neg_df = pd.read_excel(\"neg_reviews.xlsx\")\n",
    "\n",
    "pos_texts = pos_df['review'].dropna().tolist()\n",
    "neg_texts = neg_df['review'].dropna().tolist()\n",
    "\n",
    "pos_tokenized = [preprocess(text) for text in pos_texts]\n",
    "neg_tokenized = [preprocess(text) for text in neg_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "946218aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Темы по LDA: Позитивные\n",
      "Тема 1: 0.073*\"курс\" + 0.017*\"задание\" + 0.016*\"хороший\" + 0.014*\"отличный\" + 0.011*\"знание\" + 0.009*\"материал\" + 0.009*\"автор\" + 0.009*\"сложный\" + 0.009*\"понравиться\" + 0.008*\"практика\"\n",
      "Тема 2: 0.057*\"курс\" + 0.019*\"задание\" + 0.017*\"весь\" + 0.017*\"отличный\" + 0.016*\"интересный\" + 0.013*\"работа\" + 0.011*\"хороший\" + 0.011*\"материал\" + 0.010*\"полезный\" + 0.009*\"рекомендовать\"\n",
      "Тема 3: 0.066*\"курс\" + 0.037*\"задание\" + 0.013*\"материал\" + 0.013*\"сложный\" + 0.012*\"отличный\" + 0.011*\"подача\" + 0.011*\"хороший\" + 0.010*\"спасибо\" + 0.010*\"практический\" + 0.009*\"практика\"\n",
      "Тема 4: 0.027*\"курс\" + 0.016*\"работа\" + 0.012*\"дать\" + 0.008*\"системный\" + 0.008*\"возможно\" + 0.004*\"аналитик\" + 0.004*\"далёкий\" + 0.004*\"приглашение\" + 0.004*\"классный\" + 0.004*\"немного\"\n",
      "Тема 5: 0.031*\"курс\" + 0.018*\"понравиться\" + 0.016*\"тема\" + 0.013*\"задание\" + 0.011*\"материал\" + 0.008*\"урок\" + 0.008*\"интересный\" + 0.008*\"возможно\" + 0.006*\"легко\" + 0.006*\"подробно\"\n",
      "\n",
      "Темы по LDA: Негативные\n",
      "Тема 1: 0.034*\"курс\" + 0.014*\"задание\" + 0.011*\"информация\" + 0.007*\"понимать\" + 0.007*\"подробно\" + 0.007*\"сложный\" + 0.007*\"знание\" + 0.007*\"обучение\" + 0.005*\"слишком\" + 0.005*\"новичок\"\n",
      "Тема 2: 0.014*\"материал\" + 0.014*\"курс\" + 0.014*\"задание\" + 0.012*\"отвечать\" + 0.012*\"автор\" + 0.009*\"который\" + 0.009*\"вопрос\" + 0.009*\"ответ\" + 0.009*\"информация\" + 0.008*\"объяснять\"\n",
      "Тема 3: 0.026*\"курс\" + 0.013*\"материал\" + 0.010*\"задание\" + 0.008*\"вопрос\" + 0.007*\"написать\" + 0.007*\"практика\" + 0.007*\"знание\" + 0.007*\"мало\" + 0.007*\"информация\" + 0.007*\"вебинар\"\n",
      "Тема 4: 0.031*\"курс\" + 0.020*\"задание\" + 0.017*\"автор\" + 0.008*\"понравиться\" + 0.008*\"который\" + 0.006*\"плохо\" + 0.006*\"пример\" + 0.006*\"решить\" + 0.006*\"сделать\" + 0.006*\"человек\"\n",
      "Тема 5: 0.037*\"курс\" + 0.016*\"деньга\" + 0.012*\"время\" + 0.011*\"материал\" + 0.010*\"работа\" + 0.008*\"сайт\" + 0.008*\"обучение\" + 0.008*\"потратить\" + 0.006*\"тема\" + 0.006*\"объясняться\"\n"
     ]
    }
   ],
   "source": [
    "def lda_analysis(tokenized_texts, title):\n",
    "    dictionary = corpora.Dictionary(tokenized_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "    lda_model = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=15)\n",
    "\n",
    "    print(f\"\\nТемы по LDA: {title}\")\n",
    "    for idx, topic in lda_model.print_topics(-1):\n",
    "        print(f\"Тема {idx+1}: {topic}\")\n",
    "\n",
    "lda_analysis(pos_tokenized, \"Позитивные\")\n",
    "lda_analysis(neg_tokenized, \"Негативные\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "36dad7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Топики BERTopic (Позитивные):\n",
      "   Topic  Count                                        Name  \\\n",
      "0     -1     27              -1_сложный_задание_знание_курс   \n",
      "1      0     13  0_профессия_тестировщик_возможность_работа   \n",
      "2      1     10         1_автор_приятный_курс_благодарность   \n",
      "3      2      9        2_видео_хороший_особенно_видеоразбор   \n",
      "4      3      8            3_комментарий_скучно_брать_целое   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [сложный, задание, знание, курс, подробно, раз...   \n",
      "1  [профессия, тестировщик, возможность, работа, ...   \n",
      "2  [автор, приятный, курс, благодарность, большой...   \n",
      "3  [видео, хороший, особенно, видеоразбор, воспри...   \n",
      "4  [комментарий, скучно, брать, целое, момент, ре...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [ооп курс узнать узнавать неинтересно скучно м...  \n",
      "1  [отличный курс профориентация данный курс помо...  \n",
      "2  [отличный курс приятный чистый речь автор дост...  \n",
      "3  [хороший курс сначала сложно воспринимать зада...  \n",
      "4  [общий курс рекомендовать готовый регулярный с...  \n",
      "\n",
      "Топики BERTopic (Негативные):\n",
      "   Topic  Count                                   Name  \\\n",
      "0     -1     38           -1_курс_задание_автор_дизайн   \n",
      "1      0     10     0_задание_домашний_писать_странный   \n",
      "2      1     10      1_навык_желающий_разработчик_курс   \n",
      "3      2      9  2_искать_знание_приходиться_сложность   \n",
      "4      3      8     3_место_понравиться_корочка_решить   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [курс, задание, автор, дизайн, структура, нигд...   \n",
      "1  [задание, домашний, писать, странный, проводит...   \n",
      "2  [навык, желающий, разработчик, курс, ваш, учит...   \n",
      "3  [искать, знание, приходиться, сложность, инфор...   \n",
      "4  [место, понравиться, корочка, решить, потратит...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [сказать образовательный курс автор комментиро...  \n",
      "1  [часть задание иметь странный формулировка час...  \n",
      "2  [совершенно подходить человек желающий курс ус...  \n",
      "3  [информация который даваться курс научиться ра...  \n",
      "4  [решить попробовать курс эксель пробел купить ...  \n"
     ]
    }
   ],
   "source": [
    "def bertopic_analysis(texts, title):\n",
    "    tokenized = [preprocess(text) for text in texts]\n",
    "    cleaned_texts = [\" \".join(tokens) for tokens in tokenized]\n",
    "\n",
    "    model = BERTopic(language=\"multilingual\", min_topic_size=2)\n",
    "    topics, _ = model.fit_transform(cleaned_texts)\n",
    "\n",
    "    print(f\"\\nТопики BERTopic ({title}):\")\n",
    "    print(model.get_topic_info().head())\n",
    "\n",
    "    return model, topics, cleaned_texts\n",
    "\n",
    "topic_model_pos, topics_pos, pos_cleaned = bertopic_analysis(pos_texts, \"Позитивные\")\n",
    "topic_model_neg, topics_neg, neg_cleaned = bertopic_analysis(neg_texts, \"Негативные\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7dd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
